# -*- coding: utf-8 -*-
"""EDAHelper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1osT2InXhvjz3hETi9SmLDckixYeLzILO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.decomposition import PCA
from sklearn.feature_selection import VarianceThreshold
from scipy import stats

# Handling Missing Data - Multiple Methods
def fill_missing_with_strategy(df, strategy='mean'):
    """Fills missing values using SimpleImputer with a given strategy (mean, median, most_frequent)"""
    imputer = SimpleImputer(strategy=strategy)
    df[df.columns] = imputer.fit_transform(df)
    return df

def fill_missing_with_constant(df, fill_value=0):
    """Fills missing values with a constant value"""
    df.fillna(fill_value, inplace=True)
    return df

def fill_missing_with_knn(df, n_neighbors=5):
    """Fills missing values using KNNImputer"""
    imputer = KNNImputer(n_neighbors=n_neighbors)
    df[df.columns] = imputer.fit_transform(df)
    return df

def fill_missing_with_interpolation(df, method='linear'):
    """Fills missing values using interpolation (linear, polynomial, spline)"""
    df.interpolate(method=method, inplace=True)
    return df

def fill_missing_with_ffill_bfill(df):
    """Fills missing values using forward-fill and back-fill methods"""
    df.fillna(method='ffill', inplace=True)
    df.fillna(method='bfill', inplace=True)
    return df

# Encoding Categorical Data - Multiple Methods
def encode_with_label(df):
    """Encodes categorical columns using Label Encoding"""
    label_encoders = {}
    for column in df.select_dtypes(include='object').columns:
        le = LabelEncoder()
        df[column] = le.fit_transform(df[column])
        label_encoders[column] = le
    return df, label_encoders

def encode_with_onehot(df):
    """Encodes categorical columns using OneHotEncoder"""
    df = pd.get_dummies(df, drop_first=True)
    return df

def encode_with_target(df, target_col):
    """Encodes categorical columns using target mean encoding"""
    for column in df.select_dtypes(include='object').columns:
        target_means = df.groupby(column)[target_col].mean()
        df[column] = df[column].map(target_means)
    return df

# Scaling/Normalization - Multiple Methods
def scale_with_standard(df):
    """Standardizes the data to have mean=0 and variance=1"""
    scaler = StandardScaler()
    df[df.columns] = scaler.fit_transform(df)
    return df

def scale_with_minmax(df):
    """Normalizes the data to a range between 0 and 1"""
    scaler = MinMaxScaler()
    df[df.columns] = scaler.fit_transform(df)
    return df

def scale_with_robust(df):
    """Scales the data using the median and IQR, making it robust to outliers"""
    scaler = RobustScaler()
    df[df.columns] = scaler.fit_transform(df)
    return df

# Outlier Handling - Multiple Methods
def remove_outliers_zscore(df, threshold=3):
    """Removes outliers based on z-score threshold"""
    df = df[(np.abs(stats.zscore(df.select_dtypes(include=[np.number]))) < threshold).all(axis=1)]
    return df

def remove_outliers_iqr(df):
    """Removes outliers using the IQR method"""
    Q1 = df.quantile(0.25)
    Q3 = df.quantile(0.75)
    IQR = Q3 - Q1
    df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]
    return df

def cap_outliers(df, lower_quantile=0.05, upper_quantile=0.95):
    """Caps outliers based on quantiles"""
    lower_bound = df.quantile(lower_quantile)
    upper_bound = df.quantile(upper_quantile)
    df = df.clip(lower=lower_bound, upper=upper_bound, axis=1)
    return df

# Dimensionality Reduction - Multiple Methods
def reduce_dimensionality_with_pca(df, n_components=2):
    """Reduces dimensionality using PCA"""
    pca = PCA(n_components=n_components)
    df_pca = pca.fit_transform(df)
    return pd.DataFrame(data=df_pca, columns=[f'PC_{i+1}' for i in range(n_components)])

def reduce_dimensionality_with_variance_threshold(df, threshold=0.1):
    """Reduces dimensionality by removing low variance features"""
    selector = VarianceThreshold(threshold=threshold)
    df_reduced = selector.fit_transform(df)
    return pd.DataFrame(df_reduced)

# Feature Engineering - Multiple Methods
def create_polynomial_features(df, degree=2):
    """Creates polynomial features for numerical columns"""
    from sklearn.preprocessing import PolynomialFeatures
    poly = PolynomialFeatures(degree=degree)
    df_poly = poly.fit_transform(df)
    return pd.DataFrame(df_poly)

def bin_numerical(df, column, bins, labels=None):
    """Bins numerical data into discrete intervals"""
    df[f"{column}_binned"] = pd.cut(df[column], bins=bins, labels=labels)
    return df

def log_transform(df, columns):
    """Applies log transformation to reduce skewness"""
    df[columns] = np.log1p(df[columns])
    return df

# Visualization - Multiple Methods
def plot_missing_heatmap(df):
    """Visualizes missing data with a heatmap"""
    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
    plt.show()

def plot_corr_heatmap(df, method='pearson'):
    """Visualizes correlation matrix as a heatmap"""
    corr = df.corr(method=method)
    sns.heatmap(corr, annot=True, cmap='coolwarm')
    plt.show()

def plot_distributions(df):
    """Plots distribution histograms for all numerical columns"""
    df.hist(bins=30, figsize=(15, 10))
    plt.show()

def plot_boxplots(df):
    """Plots boxplots to detect outliers"""
    df.plot(kind='box', subplots=True, layout=(4, 4), figsize=(15, 10))
    plt.tight_layout()
    plt.show()

def plot_pairplot(df, target_col):
    """Plots pairwise relationships in the dataset with a target column"""
    sns.pairplot(df, hue=target_col)
    plt.show()

# Main EDA Function - Multiple Variants
def perform_basic_eda(df):
    """Performs basic EDA including correlation heatmap and distributions"""
    print("Descriptive Statistics:\n", df.describe())
    print("\nCorrelation Heatmap:")
    plot_corr_heatmap(df)
    print("\nDistributions:")
    plot_distributions(df)

def perform_advanced_eda(df, target_col):
    """Performs advanced EDA including missing heatmap, pairplots, and boxplots"""
    print("\nMissing Values Heatmap:")
    plot_missing_heatmap(df)
    print("\nBoxplots:")
    plot_boxplots(df)
    print("\nPairplot:")
    plot_pairplot(df, target_col)

